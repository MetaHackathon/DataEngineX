from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
from uuid import UUID
from datetime import datetime

# ============================================================================
# CORE USER & PAPER MODELS
# ============================================================================

class UserContext(BaseModel):
    """User context for authentication"""
    user_id: UUID
    email: Optional[str] = None
    full_name: Optional[str] = None

class PaperUploadRequest(BaseModel):
    """Request to upload a PDF paper"""
    file_name: str
    file_content: bytes
    title: Optional[str] = None
    authors: Optional[List[str]] = None
    abstract: Optional[str] = None
    year: Optional[int] = None
    topics: Optional[List[str]] = None
    source: str = "upload"  # upload, arxiv, doi

class SavedPaper(BaseModel):
    """Paper in user's research library"""
    id: UUID
    paper_id: str
    title: str
    authors: List[str]
    abstract: Optional[str] = None
    year: Optional[int] = None
    topics: List[str]
    pdf_url: str
    full_text: Optional[str] = None
    processing_status: str
    highlights_count: int = 0
    annotations_count: int = 0
    created_at: str
    updated_at: str

# ============================================================================
# INTELLIGENT SEARCH & LONG CONTEXT MODELS (NEW FOR HACKATHON)
# ============================================================================

class ResearchContext(BaseModel):
    """Comprehensive research context for intelligent search"""
    research_question: str
    user_papers: List[Dict[str, Any]] = []
    knowledge_base_papers: List[Dict[str, Any]] = []
    research_areas: List[str] = []
    methodologies: List[str] = []
    recent_searches: List[Dict[str, Any]] = []
    collaboration_context: Optional[Dict[str, Any]] = None

class IntelligentSearchRequest(BaseModel):
    """Request for intelligent ArXiv search using long context"""
    research_question: str
    knowledge_base_id: Optional[UUID] = None
    max_papers: int = 25
    include_foundational: bool = True
    include_recent: bool = True
    time_range_years: Optional[int] = None
    specific_venues: List[str] = []
    exclude_topics: List[str] = []
    methodology_focus: Optional[str] = None

class IntelligentSearchResponse(BaseModel):
    """Response from intelligent search with Llama 4 analysis"""
    papers: List[Dict[str, Any]]  # Enhanced PaperResponse with reasoning
    total_candidates: int
    query_strategies: List[Dict[str, Any]]
    research_insights: Dict[str, Any]
    processing_time: float
    confidence_score: float
    suggested_refinements: List[str] = []
    related_research_areas: List[str] = []

class LiteratureReviewRequest(BaseModel):
    """Request for comprehensive literature review generation"""
    research_focus: str
    knowledge_base_id: Optional[UUID] = None
    paper_ids: Optional[List[UUID]] = None
    user_id: UUID
    review_type: str = "comprehensive"  # comprehensive, methodology, trends, gaps
    include_citations: bool = True
    max_papers: int = 50
    focus_areas: List[str] = []

class LiteratureReviewResponse(BaseModel):
    """Comprehensive literature review generated by Llama 4"""
    title: str
    abstract: Optional[str] = None
    sections: List[Dict[str, Any]]
    conclusions: List[str]
    research_gaps: List[str]
    methodology_synthesis: str
    future_directions: List[str] = []
    paper_relationships: Dict[str, Any] = {}
    citations: List[str] = []
    generated_at: str = Field(default_factory=lambda: datetime.now().isoformat())

class KnowledgeCanvasRequest(BaseModel):
    """Request for knowledge canvas generation with deep connections"""
    knowledge_base_id: UUID
    analysis_depth: str = "deep"  # surface, moderate, deep
    include_methodology_map: bool = True
    include_timeline: bool = True
    include_research_gaps: bool = True
    include_future_directions: bool = True
    focus_areas: List[str] = []

class KnowledgeCanvasResponse(BaseModel):
    """Knowledge canvas with deep research connections"""
    canvas_id: UUID
    title: str
    paper_network: Dict[str, Any]  # Node-edge graph structure
    research_themes: List[Dict[str, Any]]
    methodology_evolution: Dict[str, Any]
    research_timeline: List[Dict[str, Any]]
    cross_paper_insights: List[Dict[str, Any]]
    research_gaps: List[Dict[str, Any]]
    future_opportunities: List[Dict[str, Any]]
    collaboration_suggestions: List[Dict[str, Any]]
    generated_at: str = Field(default_factory=lambda: datetime.now().isoformat())

class DeepConnectionAnalysisRequest(BaseModel):
    """Request for deep connection analysis between papers"""
    paper_ids: List[UUID]
    analysis_types: List[str] = ["methodology", "findings", "theoretical", "practical"]
    connection_depth: str = "deep"  # surface, moderate, deep
    include_contradictions: bool = True
    include_knowledge_gaps: bool = True

class DeepConnectionAnalysisResponse(BaseModel):
    """Deep analysis of connections between papers"""
    connections: List[Dict[str, Any]]
    themes: List[Dict[str, Any]]
    contradictions: List[Dict[str, Any]]
    knowledge_gaps: List[Dict[str, Any]]
    synthesis_opportunities: List[Dict[str, Any]]
    collaboration_potential: List[Dict[str, Any]]
    confidence_scores: Dict[str, float]

class ResearchInsightRequest(BaseModel):
    """Request for AI-powered research insights"""
    context_type: str  # "knowledge_base", "paper_collection", "search_results"
    context_id: UUID
    insight_types: List[str] = ["trends", "gaps", "opportunities", "methodologies", "collaborations"]
    time_horizon: str = "mixed"  # historical, current, future, mixed
    include_actionable_suggestions: bool = True

class ResearchInsightResponse(BaseModel):
    """AI-generated research insights using long context"""
    insights: List[Dict[str, Any]]
    trending_topics: List[Dict[str, Any]]
    emerging_methodologies: List[Dict[str, Any]]
    research_opportunities: List[Dict[str, Any]]
    collaboration_suggestions: List[Dict[str, Any]]
    actionable_next_steps: List[str]
    confidence_assessment: Dict[str, float]
    supporting_evidence: Dict[str, List[str]]

# ============================================================================
# ANNOTATIONS & HIGHLIGHTS
# ============================================================================

class CreateHighlightRequest(BaseModel):
    """Request to create a highlight in a paper"""
    paper_id: UUID
    text: str
    page_number: int
    position: Dict[str, Any]  # {start, end, rects: [{x, y, width, height}]}
    color: str = "yellow"

class HighlightResponse(BaseModel):
    """Highlight information"""
    id: UUID
    paper_id: UUID
    text: str
    page_number: int
    position: Dict[str, Any]
    color: str
    created_at: str

class CreateAnnotationRequest(BaseModel):
    """Request to create an annotation"""
    paper_id: UUID
    content: str
    highlight_id: Optional[UUID] = None
    annotation_type: str = "note"  # note, question, insight, critique
    page_number: Optional[int] = None
    position: Optional[Dict[str, Any]] = None
    tags: List[str] = []

class AnnotationResponse(BaseModel):
    """Annotation information"""
    id: UUID
    paper_id: UUID
    highlight_id: Optional[UUID] = None
    content: str
    annotation_type: str
    page_number: Optional[int] = None
    position: Optional[Dict[str, Any]] = None
    tags: List[str]
    created_at: str
    updated_at: str

# ============================================================================
# CHAT & ANALYSIS
# ============================================================================

class ChatSessionRequest(BaseModel):
    """Request to create a chat session"""
    paper_id: Optional[UUID] = None
    session_name: Optional[str] = None
    session_type: str = "paper"  # paper, collection, general

class ChatMessageRequest(BaseModel):
    """Request to send a chat message"""
    session_id: UUID
    message: str
    include_context: bool = True

class ChatMessageResponse(BaseModel):
    """Chat message response"""
    id: UUID
    session_id: UUID
    role: str  # user, assistant
    content: str
    sources: List[Dict[str, Any]] = []
    created_at: str

class ChatSessionResponse(BaseModel):
    """Chat session information"""
    id: UUID
    paper_id: Optional[UUID] = None
    session_name: str
    session_type: str
    messages_count: int
    created_at: str
    updated_at: str

# ============================================================================
# ANALYSIS & INSIGHTS
# ============================================================================

class AnalysisRequest(BaseModel):
    """Request to analyze a paper"""
    paper_id: UUID
    analysis_type: str = "summary"  # summary, key_points, methodology, critique
    focus_areas: List[str] = []

class AnalysisResponse(BaseModel):
    """Analysis result"""
    id: UUID
    paper_id: UUID
    analysis_type: str
    content: str
    insights: List[str]
    key_quotes: List[Dict[str, Any]]
    related_concepts: List[str]
    created_at: str

class CompareRequest(BaseModel):
    """Request to compare papers"""
    paper_ids: List[UUID]
    comparison_type: str = "methodology"  # methodology, results, approaches

class ComparisonResponse(BaseModel):
    """Comparison result"""
    papers: List[SavedPaper]
    similarities: List[str]
    differences: List[str]
    synthesis: str
    recommendations: List[str]

# ============================================================================
# CONCEPTS & KNOWLEDGE GRAPH
# ============================================================================

class CreateConceptRequest(BaseModel):
    """Request to create a concept"""
    name: str
    description: Optional[str] = None
    concept_type: str = "user_defined"
    color: str = "#3B82F6"

class ConceptResponse(BaseModel):
    """Concept information"""
    id: UUID
    name: str
    description: Optional[str] = None
    concept_type: str
    color: str
    linked_papers: int
    linked_annotations: int
    created_at: str
    updated_at: str

class LinkConceptRequest(BaseModel):
    """Request to link a concept to content"""
    concept_id: UUID
    entity_type: str  # paper, annotation, highlight
    entity_id: UUID
    relevance_score: float = 1.0

# ============================================================================
# RESEARCH COLLECTIONS & WORKFLOWS
# ============================================================================

class CreateCollectionRequest(BaseModel):
    """Request to create a research collection"""
    name: str
    description: Optional[str] = None
    paper_ids: List[UUID] = []
    is_public: bool = False

class CollectionResponse(BaseModel):
    """Research collection information"""
    id: UUID
    name: str
    description: Optional[str] = None
    papers_count: int
    is_public: bool
    created_at: str
    updated_at: str

# ============================================================================
# SEARCH & DISCOVERY
# ============================================================================

class SearchRequest(BaseModel):
    """Request to search within user's library"""
    query: str
    search_in: List[str] = ["papers", "annotations", "highlights"]
    paper_ids: Optional[List[UUID]] = None
    limit: int = 20

class SearchResult(BaseModel):
    """Search result item"""
    id: UUID
    type: str  # paper, annotation, highlight
    title: str
    content: str
    paper_id: UUID
    paper_title: str
    relevance_score: float
    page_number: Optional[int] = None
    created_at: str

class SearchResponse(BaseModel):
    """Search results"""
    query: str
    total_results: int
    results: List[SearchResult]
    search_time: float

# ============================================================================
# SYSTEM RESPONSES
# ============================================================================

class PaperProcessResponse(BaseModel):
    """Response after processing a paper"""
    success: bool
    message: str
    paper: SavedPaper
    analysis_preview: Optional[str] = None
    processing_time: float

class LibraryStatsResponse(BaseModel):
    """User's research library statistics"""
    total_papers: int
    total_annotations: int
    total_highlights: int
    total_concepts: int
    total_collections: int
    recent_activity: List[Dict[str, Any]]
    storage_used_mb: float
    last_updated: str

# ============================================================================
# KNOWLEDGE BASE MANAGEMENT (NEW - Required by Frontend)
# ============================================================================

class CreateKnowledgebaseRequest(BaseModel):
    """Request to create a new knowledge base"""
    name: str
    description: Optional[str] = None
    papers: List[str] = []  # List of paper IDs
    tags: List[str] = []
    is_public: bool = False

class KnowledgebaseResponse(BaseModel):
    """Knowledge base information"""
    id: UUID
    name: str
    description: Optional[str] = None
    paper_count: int
    created_at: str
    updated_at: str
    tags: List[str]
    status: str = "active"
    user_id: UUID
    is_public: bool

class UpdateKnowledgebaseRequest(BaseModel):
    """Request to update a knowledge base"""
    name: Optional[str] = None
    description: Optional[str] = None
    papers: Optional[List[str]] = None
    tags: Optional[List[str]] = None
    is_public: Optional[bool] = None

class AddPapersToKnowledgebaseRequest(BaseModel):
    """Request to add papers to knowledge base"""
    paper_ids: List[str]

class RemovePapersFromKnowledgebaseRequest(BaseModel):
    """Request to remove papers from knowledge base"""
    paper_ids: List[str]

class ShareKnowledgebaseRequest(BaseModel):
    """Request to share a knowledge base"""
    email: Optional[str] = None
    permissions: str  # 'read', 'write', 'admin'
    public_link: bool = False

class KnowledgebaseInsightsResponse(BaseModel):
    """AI-generated insights for a knowledge base"""
    id: UUID
    knowledgebase_id: UUID
    insights: List[Dict[str, Any]]
    trends: List[str]
    research_gaps: List[str]
    key_connections: List[Dict[str, Any]]
    generated_at: str

# ============================================================================
# ENHANCED DOCUMENT & ANNOTATION MODELS (Enhanced for Frontend)
# ============================================================================

class DocumentResponse(BaseModel):
    """Document information for viewer"""
    id: UUID
    title: str
    authors: List[str]
    pdfUrl: str
    abstract: Optional[str] = None
    year: Optional[int] = None
    topics: List[str] = []
    page_count: Optional[int] = None
    processing_status: str = "completed"

class HighlightRequest(BaseModel):
    """Request to create a highlight"""
    content: Dict[str, Any]  # {text?: string, image?: string}
    position: Dict[str, Any]  # Position data from PDF viewer
    color: str = "#FFFF00"
    type: str = "text"  # 'text' | 'area'
    comment: Optional[str] = None

class HighlightUpdateRequest(BaseModel):
    """Request to update a highlight"""
    comment: Optional[str] = None
    color: Optional[str] = None

class DocumentAnnotationRequest(BaseModel):
    """Request to create document annotation"""
    type: str  # 'note' | 'bookmark' | 'comment'
    content: str
    page: int
    position: Optional[Dict[str, Any]] = None

class DocumentChatRequest(BaseModel):
    """Request to send chat message about document"""
    message: str
    context: Optional[Dict[str, Any]] = None  # {highlights?: string[], page?: number}

class DocumentChatResponse(BaseModel):
    """Response from document chat"""
    id: UUID
    message: str
    sources: List[Dict[str, Any]] = []
    timestamp: str

# ============================================================================
# ENHANCED SEARCH MODELS (Enhanced for Frontend)
# ============================================================================

class EnhancedSearchRequest(BaseModel):
    """Enhanced search request with filters"""
    query: str
    search_in: List[str] = ["papers", "annotations", "highlights"]
    paper_ids: Optional[List[UUID]] = None
    limit: int = 20
    quality_filter: Optional[int] = None
    year_range: Optional[Dict[str, int]] = None  # {min: 2020, max: 2024}
    topics: Optional[List[str]] = None
    sort_by: str = "relevance"  # relevance, date, citations, quality

class EnhancedPaperResponse(BaseModel):
    """Enhanced paper response with quality scores"""
    id: str
    title: str
    abstract: Optional[str] = None
    authors: List[str]
    year: int
    citations: int = 0
    institution: Optional[str] = None
    impact: str = "low"
    url: str
    topics: List[str] = []
    qualityScore: Optional[int] = None
    relevanceScore: Optional[int] = None
    venue: Optional[str] = None
    connections: List[str] = []
    keyInsights: List[str] = []

# ============================================================================
# ENHANCED DASHBOARD MODELS (Enhanced for Frontend)
# ============================================================================

class EnhancedLibraryStatsResponse(BaseModel):
    """Enhanced user's research library statistics"""
    total_papers: int
    total_annotations: int
    total_highlights: int
    total_concepts: int
    total_collections: int
    total_knowledgebases: int
    total_chat_sessions: int
    recent_activity: List[Dict[str, Any]]
    storage_used_mb: float
    research_metrics: Dict[str, Any]  # quality scores, trending topics, etc.
    last_updated: str

class DashboardResponse(BaseModel):
    """Dashboard data with activity and insights"""
    recent_papers: List[EnhancedPaperResponse]
    recent_annotations: List[Dict[str, Any]]
    suggested_papers: List[EnhancedPaperResponse]
    active_research_areas: List[str]
    reading_progress: Dict[str, Any]
    ai_insights: List[Dict[str, Any]]
    quick_stats: EnhancedLibraryStatsResponse

# ============================================================================
# EXPORT MODELS (New for Frontend)
# ============================================================================

class ExportRequest(BaseModel):
    """Request to export data"""
    format: str  # 'json', 'csv', 'bibtex'
    include_annotations: bool = True
    include_highlights: bool = True

class ExportResponse(BaseModel):
    """Export response"""
    download_url: str
    expires_at: str
    file_size: int
    format: str 